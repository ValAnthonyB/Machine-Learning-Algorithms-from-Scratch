{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80511374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc22095",
   "metadata": {},
   "source": [
    "# Näive Bayes Classifier\n",
    "\n",
    "Given a feature vector $\\vec{x}$, we want to know which of all the classes is most likely (*main problem*). Essentially, we want to answer the following questions: \n",
    "<br><br>\n",
    "\\begin{equation}\n",
    "    \\text{argmax}_{k \\in K} P(C=k|\\vec{x})\n",
    "\\end{equation}\n",
    "<br><br>\n",
    "where $C$ is a random variable representing the class of the data. Using Bayes' theorem, we have an expression for $P(C=k|\\vec{x})$:\n",
    "<br><br>\n",
    "\\begin{equation}\n",
    "    P(C=k|\\vec{x}) = P(C=k) \\frac{P(\\vec{x}|C=k)}{P(\\vec{x})}\n",
    "\\end{equation}\n",
    "<br><br>\n",
    "We note that\n",
    "\n",
    "* $P(C=k|\\vec{x})$ - posterior probability\n",
    "* $P(C=k)$ - prior\n",
    "* $P(\\vec{x}|C=k)$ - likelihood\n",
    "* $P(\\vec{x})$ - evidence\n",
    "\n",
    "We note that $\\vec{x}$ is also a stochastic or random variable. Suppose that $\\vec{x} \\in \\mathbb{R}^n$, then we can expand the numerator using the Chain Rule of probability assuming that the **features are independent** (this is called the Näive assumption)\n",
    "<br><br>\n",
    "\\begin{align}\n",
    "    P(x_1, x_2, \\ldots, x_n|C=k) = P(C=k) P(\\vec{x}|C=k)\n",
    "\\end{align}\n",
    "<br><br>\n",
    "Applying the chain rule multiple times:\n",
    "<br><br>\n",
    "\\begin{align}\n",
    "    P(C=k) P(\\vec{x}|C=k) &= P(x_1|x_2, \\ldots, x_n, C=k) P(x_2, \\ldots, x_n, C=k)\\\\\n",
    "                                &= P(x_1|x_2, \\ldots, x_n, C=k) P(x_2|x_3, \\ldots, x_n,C=k) \\cdots P(x_n|C=k) P(C=k)\\\\\n",
    "    P(C=k) P(\\vec{x}|C=k) &= P(C=k) \\prod_{i=1}^n P(x_i|C=k)\n",
    "\\end{align}\n",
    "<br><br>\n",
    "Therefore, we have:\n",
    "<br><br>\n",
    "\\begin{align}\n",
    "    P(C=k|\\vec{x}) = \\frac{P(C=k)}{P(\\vec{x})} \\prod_{i=1}^n P(x_i|C=k)\n",
    "\\end{align}\n",
    "<br><br>\n",
    "Hence, the problem reduces to\n",
    "<br><br>\n",
    "\\begin{align}\n",
    "    \\text{argmax}_{k \\in K} P(C=k) \\prod_{i=1}^n P(x_i|C=k)\n",
    "\\end{align}\n",
    "<br><br>\n",
    "We can drop the term $P(\\vec{x})$ in the denominator because it is not dependent on $k$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75859d5c",
   "metadata": {},
   "source": [
    "# Spam Filters\n",
    "\n",
    "A spam filter is a classification problem with two classes: spam and ham (not spam). Let's go into detail as to how to solve:\n",
    "<br><br>\n",
    "\\begin{align}\n",
    "    \\text{argmax}_{k \\in K} P(C=k) \\prod_{i=1}^n P(x_i|C=k)\n",
    "\\end{align}\n",
    "<br><br>\n",
    "We note that we have a labeled training set to determine $P(C=\\text{spam})$, the probability of spam, and $P(C=\\text{ham})$, the probability of ham. To do this, **we assume that the training set is a representative sample** and define\n",
    "<br><br>\n",
    "\\begin{align}\n",
    "    P(C=\\text{spam}) = \\frac{N_{\\text{spam}}}{m}\n",
    "\\end{align}\n",
    "<br><br>\n",
    "and \n",
    "<br><br>\n",
    "\\begin{align}\n",
    "    P(C=\\text{ham}) = \\frac{N_{\\text{ham}}}{m}\n",
    "\\end{align}\n",
    "<br><br>\n",
    "where $m$ is the number of samples in the dataset. Using a bag of words model, we can create a simple representation of $P(x_i|C=k)$ where $x_i$ is the $i$th word in a message (one-hot vector), and therefore $\\vec{x}$ is the entire message. This results in the simple definition:\n",
    "<br><br>\n",
    "\\begin{align}\n",
    "    P(x_i|C=k) = \\frac{N_{\\text{occurences of $x_i$ in class $k$}}}{N_{\\text{words in class $k$}}}\n",
    "\\end{align}\n",
    "<br><br>\n",
    "We note that the denominator is the total number of occurences of *any* word in class $k$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0725d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesFilter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # Class Methods\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        X: pd.Series\n",
    "        y: pd.Series\n",
    "        '''\n",
    "        # Probability of spam\n",
    "        self.P_spam = len(y[y=='spam']) / len(y)\n",
    "        \n",
    "        # Probability of ham\n",
    "        self.P_ham = len(y[y=='ham']) / len(y)\n",
    "        \n",
    "        # Filter the spam and ham data from X\n",
    "        X_spam = X[y=='spam'].reset_index()\n",
    "        X_spam.drop('index', axis=1, inplace=True)\n",
    "        X_spam['Message'] = X_spam['Message'].str.lower()\n",
    "        \n",
    "        X_ham = X[y=='ham'].reset_index()\n",
    "        X_ham.drop('index', axis=1, inplace=True)\n",
    "        X_ham['Message'] = X_ham['Message'].str.lower()\n",
    "        \n",
    "        # Get the counts for each class\n",
    "        count_spam = self.__counts(X_spam)\n",
    "        count_ham = self.__counts(X_ham)\n",
    "        \n",
    "        # Get the unique words\n",
    "        self.unique_words = sorted(list( set(count_ham.keys()) | set(count_spam.keys()) ))\n",
    "        \n",
    "        # Get the words not in spam but in ham, vice versa\n",
    "        keys_not_in_spam = list(set(count_ham.keys()).difference(list(count_spam.keys()))) # keys in ham that are not in spam\n",
    "        keys_not_in_ham = list(set(count_spam.keys()).difference(list(count_ham.keys())))\n",
    "        \n",
    "        # For the keys not in spam, automatically set to 0\n",
    "        for not_key in keys_not_in_spam:\n",
    "            count_spam[not_key] = 0\n",
    "\n",
    "        for not_key in keys_not_in_ham:\n",
    "            count_ham[not_key] = 0\n",
    "            \n",
    "        # Sort the keys of the dictionaries\n",
    "        count_spam = dict(sorted(count_spam.items()))\n",
    "        count_ham = dict(sorted(count_ham.items()))\n",
    "        \n",
    "        # Construct the final dataframe\n",
    "        data = pd.DataFrame(columns=count_spam.keys(), index=['spam','ham'])\n",
    "        data.loc['spam'] = list(count_spam.values())\n",
    "        data.loc['ham'] = list(count_ham.values())\n",
    "        \n",
    "        self.data = data\n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        '''\n",
    "        In this method, we want to calculate proba = [P(Spam|x), P(Ham|x)].\n",
    "        \n",
    "        Input:\n",
    "            X: pd.Series\n",
    "                    - Represents new data that needs to be classified. The data is a series of messages.\n",
    "        '''\n",
    "        \n",
    "        # Computes [P(Spam|x), P(Ham|x)] for each message x in dataset X\n",
    "        proba = np.zeros((len(X), 2))\n",
    "        for i, x in enumerate(X):\n",
    "            prod_spam_x = 1\n",
    "            prod_ham_x = 1\n",
    "            for word in x:\n",
    "                if word in self.unique_words:\n",
    "                    prod_spam_x *= self.data.loc['spam', word] / self.data.loc['spam'].sum()\n",
    "                    prod_ham_x *= self.data.loc['ham', word] / self.data.loc['ham'].sum()\n",
    "                    \n",
    "                else: # Word is not in the dictionary (unknown)\n",
    "                    prod_spam_x *= 1\n",
    "                    prod_ham_x *= 1\n",
    "            \n",
    "            proba[i] = np.array([self.P_spam * prod_spam_x, self.P_ham * prod_ham_x])\n",
    "                \n",
    "        # Returns [P(Spam|x), P(Ham|x)] for each message in x\n",
    "        return proba\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Gets the probabilities\n",
    "        probas = self.predict_proba(X)\n",
    "        \n",
    "        # Predicts the class of each example\n",
    "        pred_classes = []\n",
    "        for i in probas:\n",
    "            result = np.argmax(i) \n",
    "            if result == 0:\n",
    "                pred_classes.append('spam')\n",
    "            else:\n",
    "                pred_classes.append('ham')\n",
    "            \n",
    "        return np.array(pred_classes)\n",
    "    \n",
    "    \n",
    "    def predict_log_proba(self, X):\n",
    "        log_proba = np.zeros((len(X), 2))\n",
    "        for i, x in enumerate(X):\n",
    "            sum_spam_x = 0\n",
    "            sum_ham_x = 0\n",
    "            for word in x:\n",
    "                if word in self.unique_words:\n",
    "                    sum_spam_x += np.log((self.data.loc['spam', word] + 1) / (self.data.loc['spam'].sum() + 2))\n",
    "                    sum_ham_x += np.log((self.data.loc['ham', word] + 1) / (self.data.loc['ham'].sum() + 2))\n",
    "                    \n",
    "                else: # Word is not in the dictionary (unknown)\n",
    "                    sum_spam_x += np.log(1)\n",
    "                    sum_ham_x += np.log(1)\n",
    "                \n",
    "        return log_proba\n",
    "    \n",
    "    \n",
    "    def predict_log(self, X):\n",
    "        # Gets the probabilities\n",
    "        log_probas = self.predict_log_proba(X)\n",
    "        \n",
    "        # Predicts the class of each example\n",
    "        pred_classes = []\n",
    "        for i in log_probas:\n",
    "            result = np.argmax(i) \n",
    "            if result == 0:\n",
    "                pred_classes.append('spam')\n",
    "            else:\n",
    "                pred_classes.append('ham')\n",
    "            \n",
    "        return np.array(pred_classes)\n",
    "    \n",
    "    \n",
    "    # Secret methods\n",
    "    def __counts(self, df):\n",
    "        results = Counter()\n",
    "        df['Message'].str.lower().str.split().apply(results.update)\n",
    "        \n",
    "        return dict(sorted(results.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c2883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c9258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c45dc9b",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "627c4eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                            Message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/spam.csv', encoding = \"ISO-8859-1\", usecols=['Class', 'Message'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ef8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7d596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98c40c97",
   "metadata": {},
   "source": [
    "# Select the features and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47cba8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.Message\n",
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c969b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71767cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58bb4661",
   "metadata": {},
   "source": [
    "# Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f626571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = NaiveBayesFilter()\n",
    "NB.fit(X[:300], y[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c707c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579bb866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93c3b5d2",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7926202",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = NB.predict(X[5000:5500])\n",
    "y_true = y[5000:5500].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a4df94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd38b410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c74dd18a",
   "metadata": {},
   "source": [
    "# Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e3522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24b303d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc8ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ece8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6f5866d",
   "metadata": {},
   "source": [
    "# Underflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9325c7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+000, 2.46881184e-176],\n",
       "       [0.00000000e+000, 1.18335326e-075]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.predict_proba(X[[1085, 2010]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ea2fb2",
   "metadata": {},
   "source": [
    "##### Use predict_log insead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e236ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam', 'spam'], dtype='<U4')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB.predict_log(X[[1085, 2010]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f1eb83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ba6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
