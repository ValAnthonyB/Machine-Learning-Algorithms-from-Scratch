{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fceb6ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098fcb05",
   "metadata": {},
   "source": [
    "# Make regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb3b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples=20, n_features=2, noise=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb26d3",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9fd042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionClass:\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "        self.intercept_ = 0\n",
    "        \n",
    "    # Class Methods\n",
    "    def fit(self, X, y, α=0.1, max_iter=10**6, tols=10e-8):\n",
    "        '''\n",
    "            Looks for the best coefficients given the data using batch gradient descent.\n",
    "        '''\n",
    "        m, n = X.shape # number of rows (data points), number of features\n",
    "        \n",
    "        # Random initial guess for the weights and bias\n",
    "        old_weights = np.random.rand(n) \n",
    "        old_bias = 0\n",
    "        \n",
    "        # Gradient descent\n",
    "        for iteration in range(max_iter):\n",
    "            new_weights = old_weights - α * (1/m) * np.dot(X.T, (np.dot(X, old_weights) + old_bias - y) )\n",
    "            new_bias = old_bias - α * (1/m) * np.sum(np.dot(X, old_weights) + old_bias - y)\n",
    "            \n",
    "            # Stopping criterion\n",
    "            if (np.linalg.norm(new_weights - old_weights) > tols) and (np.abs(new_bias - old_bias) > tols):\n",
    "                old_weights = new_weights\n",
    "                old_bias = new_bias\n",
    "\n",
    "            else:\n",
    "                print(\"Converged after {} iterations.\".format(iteration))\n",
    "                # Best Model Coefficients\n",
    "                self.coef_ = new_weights \n",
    "                self.intercept_ = new_bias\n",
    "                \n",
    "                break\n",
    "\n",
    "        # Compute for the linear regression model's score\n",
    "        predicted_y = np.array([np.dot(Xi, self.coef_) + self.intercept_ for Xi in X]) # predicted y for the X[i] data\n",
    "\n",
    "        SS_res = np.sum((y - predicted_y)**2)    \n",
    "        SS_tot = np.sum((y - y.mean())**2)\n",
    "        self.R2 = 1 - (SS_res/SS_tot) # Model Score\n",
    "    \n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        #x = np.insert(x_test, 0, 1)\n",
    "        return np.dot(x_test, self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfebe0d0",
   "metadata": {},
   "source": [
    "## Learn and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba0e7fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 2904 iterations.\n",
      "[87.10640654 76.74078338] 0.927455756767012\n"
     ]
    }
   ],
   "source": [
    "# Feed the data to the linear regression model with random initial parameters\n",
    "regtest = LinearRegressionClass() \n",
    "regtest.fit(X, y,α=0.01) # Learn from data\n",
    "\n",
    "# Print the coefficients and model score\n",
    "print(regtest.coef_, regtest.R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85d63a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.679751739342024"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a prediction\n",
    "test_case = np.random.rand(len(X[0]))\n",
    "regtest.predict(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2e74a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9a9e1ac",
   "metadata": {},
   "source": [
    "# Compare with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dfb34a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.302042098868753 [87.10645801 76.74075753] 0.9274557567671048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46.67977996784127"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "print(reg.intercept_, reg.coef_, reg.score(X, y))\n",
    "reg.predict(np.array([test_case]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2679a036",
   "metadata": {},
   "source": [
    "### In good agreement! Also works for higher-dimensional data although the code will run much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ef75a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
